{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, all course GitHub pages URLs are given as a list in order to be scraped individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Aug 20 11:45:03 2020\n",
    "\n",
    "@author: simondonike\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "url_list = [\n",
    "\"https://eo4geocourses.github.io/PLUS_Practice-Image-Processing/\",\n",
    "\"https://eo4geocourses.github.io/VITO_TerraScope_TrainingPack_Application_Example/\",\n",
    "\"https://eo4geocourses.github.io/VITO_Data_Access_In_Terrascope/\",\n",
    "\"https://eo4geocourses.github.io/VITO_Cloud_Infrastructure/\",\n",
    "\"https://eo4geocourses.github.io/GISIG_Introduction_to_EO4GEO/\",\n",
    "\"https://eo4geocourses.github.io/SpaSe_OBIA-for-Operations-Copernicus-Service-Challenge-Practical-Example/\",\n",
    "\"https://eo4geocourses.github.io/GEOF_Understanding-the-concept-of-EO-time-series/\",\n",
    "\"https://eo4geocourses.github.io/GEOF_Basic-GIS-knowledge-vector-and-raster-data/\",\n",
    "\"https://eo4geocourses.github.io/GEOF_Copernicus-Service-Land/\",\n",
    "\"https://eo4geocourses.github.io/GEOF_EO-Data-sources/\",\n",
    "\"https://eo4geocourses.github.io/GEOF_Validation-of-EO-products/\",\n",
    "\"https://eo4geocourses.github.io/GEOF_Preprocessing-of-EO-data/\",\n",
    "\"https://eo4geocourses.github.io/GEOF_Legal-issues-in-EO-GI/\",\n",
    "\"https://eo4geocourses.github.io/UT-ITC_Satellite_Data_Classification_Random_Forests/\",\n",
    "\"https://eo4geocourses.github.io/UT-ITC_Satellite_Data_Classification_Decision_Trees/\",\n",
    "\"https://eo4geocourses.github.io/UNEP-GRID_Introduction-to-GIS/\",\n",
    "\"https://eo4geocourses.github.io/KULeuven_Technical-Introduction-to-SDI/\",\n",
    "\"https://eo4geocourses.github.io/KULeuven_Management-View-on-SDI/\",\n",
    "\"https://eo4geocourses.github.io/KULeuven_Introduction-CitizenScience-in-GI-and-EO/\",\n",
    "\"https://eo4geocourses.github.io/IGIK_Sentinel2-Data-and-Vegetation-Indices/\",\n",
    "\"https://eo4geocourses.github.io/IGIK_Introduction-to-Remote-Sensing/\",\n",
    "\"https://eo4geocourses.github.io/ClimateKIC_Copernicus-Service-Climate-Change/\",\n",
    "\"https://eo4geocourses.github.io/ClimateKIC_Copernicus-Service-Atmosphere/\",\n",
    "\"https://eo4geocourses.github.io/IES_EO-for-Managers/\",\n",
    "\"https://eo4geocourses.github.io/FSU-Jena_Persistent-Scaterrer-Interferometry/\",\n",
    "\"https://eo4geocourses.github.io/FSU-Jena_SAR-Data-for-Flood-Mapping/\",\n",
    "\"https://eo4geocourses.github.io/ROSA_Change-Detection-in-optical-Data/\",\n",
    "\"https://eo4geocourses.github.io/UNIBAS_Remote-Sensing-Environment/\",\n",
    "\"https://eo4geocourses.github.io/UNIBAS_Methods-Techniques-EO/\",\n",
    "\"https://eo4geocourses.github.io/UJI_Introduction-to-Programming/\",\n",
    "\"https://eo4geocourses.github.io/UJI_Reproducable-Research-Practices-in-Geosciences/\",\n",
    "\"https://eo4geocourses.github.io/UJI_AgroMonitoring-with-Geospatial-Data/\",\n",
    "\"https://eo4geocourses.github.io/PLUS_EO_For_Natural_Hazards/\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, a function is defined which extracts the HTML code for any given URL. the second funtion extracts the Metadata section from the HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Takes URL, returns HTML as string\"\"\"\n",
    "def get_html(url):\n",
    "    url_answer = requests.get(url)\n",
    "    print(url_answer,\"  received from GitHub Pages ->\",url[32:])\n",
    "    htmltext = url_answer.text\n",
    "    return(htmltext)\n",
    "\n",
    "\n",
    "\"\"\"Extracts MetaData part ftom full HTML text, removes formatiing characters\"\"\"\n",
    "def extract_metadata(htmltext):\n",
    "    metadata_start = htmltext[htmltext.find(\"AUTHORS: DEFINE METADATA FOR WHOLE SLIDESET HERE:\"):]\n",
    "    metadata_end = metadata_start[:metadata_start.find(\"-->\",50)]\n",
    "    metadata = metadata_end\n",
    "    #removing new line and tab characters\n",
    "    metadata = metadata.replace(\"\\n\",\"\")\n",
    "    metadata = metadata.replace(\"\\t\",\"\")\n",
    "    \n",
    "    return(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, funtions for each information are created. These funtions extract the information in question and return them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Extracts string after dc:title, returns MAX 1 argument\"\"\"\n",
    "def extract_title(metadata):\n",
    "    metadata_short = metadata[metadata.find(\"dc:title \")+(len(\"dc:title \")+1):]\n",
    "    title = metadata_short[:metadata_short.find('\"')]\n",
    "    return(title)\n",
    "\n",
    "\"\"\"Extracts string after dc:creator, returns MAX 1 argument\"\"\"\n",
    "def extract_creator(metadata):\n",
    "    metadata_short = metadata[metadata.find(\"dc:creator \")+(len(\"dc:creator \")+1):]\n",
    "    creator = metadata_short[:metadata_short.find('\"')]\n",
    "    return(creator)\n",
    "\n",
    "\"\"\"Extracts string after dc:abstract, returns MAX 1 argument\"\"\"\n",
    "def extract_abstract(metadata):\n",
    "    metadata_short = metadata[metadata.find(\"dc:abstract \")+(len(\"dc:abstract \")+1):]\n",
    "    abstract = metadata_short[:metadata_short.find('\"')]\n",
    "    return(abstract)\n",
    "\n",
    "\"\"\"Extracts string after dc:description, returns MAX 1 argument\"\"\"\n",
    "def extract_description(metadata):\n",
    "    metadata_short = metadata[metadata.find(\"dc:description \")+(len(\"dc:description \")+1):]\n",
    "    description = metadata_short[:metadata_short.find('\"')]\n",
    "    return(description)\n",
    "\n",
    "\"\"\"Extracts string after dc:contributor, returns MAX 1 argument\"\"\"\n",
    "def extract_contributor(metadata):\n",
    "    metadata_short = metadata[metadata.find(\"dc:contributor \")+(len(\"dc:contributor \")+1):]\n",
    "    contributor = metadata_short[:metadata_short.find('\"')]\n",
    "    return(contributor)\n",
    "\n",
    "\"\"\"Extracts string after dc:created, returns MAX 1 argument\"\"\"\n",
    "def extract_created(metadata):\n",
    "    metadata_short = metadata[metadata.find(\"dc:created \")+(len(\"dc:created \")+1):]\n",
    "    created = metadata_short[:metadata_short.find('\"')]\n",
    "    return(created)\n",
    "\n",
    "\"\"\"Extracts string after dc:language, returns MAX 1 argument\"\"\"\n",
    "def extract_language(metadata):\n",
    "    metadata_short = metadata[metadata.find(\"dc:language \")+(len(\"dc:language \")+1):]\n",
    "    language = metadata_short[:metadata_short.find('\"')]\n",
    "    return(language)\n",
    "\n",
    "\"\"\"Extracts strings after dc:relations, returns LIST of arguments (relations)\"\"\"\n",
    "def extract_relation(metadata):\n",
    "    relation = []\n",
    "    #Cycling through metadata while stil relation left, taking relation out of\n",
    "    #string after appending to relation list\n",
    "    while \"dc:relation\" in metadata:\n",
    "        metadata_short = metadata[metadata.find(\"dc:relation\")+(len(\"dc:relation \")):]\n",
    "        temp = (metadata_short[:metadata_short.find(\";\")]).replace(\"eo4geo:\",\"\")\n",
    "        \n",
    "        # Checking for finish of last relation , either \" \" \";\" or \".\"\n",
    "        # in order to slice string after last relation\n",
    "        if \" \" in temp:\n",
    "            temp = temp[:temp.find(\" \")]\n",
    "        if \".\" in temp:\n",
    "            temp = temp[:temp.find(\".\")]\n",
    "        \n",
    "        relation.append(temp)\n",
    "        metadata = metadata_short[metadata_short.find(\";\"):]\n",
    "    \n",
    "    return(relation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scrape function is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Takes List, returns list of metadata.\n",
    "for each item in list:\n",
    "item[0] = URL\n",
    "item[1] = changed? True/False\n",
    "item[2] = title\n",
    "item[3] = creator\n",
    "item[4] = abstract\n",
    "item[5] = description\n",
    "item[6] = contributors\n",
    "item[7] = created\n",
    "item[8] = relation\n",
    "item[9] = language\n",
    "\"\"\"\n",
    "def scrape(url_list):\n",
    "    ls = []\n",
    "    for url in url_list:\n",
    "        item = []\n",
    "        item.append(str(url))\n",
    "        htmltext = get_html(url)\n",
    "        metadata = extract_metadata(htmltext)\n",
    "        #print(metadata)\n",
    "        if extract_title(metadata) == \"What is Copernicus?\":\n",
    "            #print(\"UNCHANGED\",url)\n",
    "            changed_metadata = False\n",
    "            item.append(str(changed_metadata)) #status\n",
    "            item.append(\"\")             #title\n",
    "            item.append(\"\")             #creator\n",
    "            item.append(\"\")             #abstract\n",
    "            item.append(\"\")             #desctiption\n",
    "            item.append(\"\")             #contributor\n",
    "            item.append(\"\")             #created\n",
    "            item.append(\"\")             #relation\n",
    "            item.append(\"\")             #language\n",
    "            \"\"\"\n",
    "            dict_meta = {}\n",
    "            dict_meta[\"title\"] = \"\"\n",
    "            dict_meta[\"creator\"] = \"\"\n",
    "            dict_meta[\"abstract\"] = \"\"\n",
    "            dict_meta[\"description\"] = \"\"\n",
    "            dict_meta[\"contributor\"] = \"\"\n",
    "            dict_meta[\"created\"] = \"\"\n",
    "            dict_meta[\"relation\"] = \"\"\n",
    "            item.append(dict_meta)\n",
    "            \"\"\"\n",
    "        else:\n",
    "            changed_metadata = True\n",
    "            #print(\"CHANGED\",url)\n",
    "            item.append(str(changed_metadata))               #status\n",
    "            item.append(extract_title(metadata))        #title\n",
    "            item.append(extract_creator(metadata))      #creator\n",
    "            item.append(extract_abstract(metadata))     #abstract\n",
    "            item.append(extract_description(metadata))  #description\n",
    "            item.append(extract_contributor(metadata))  #contributors\n",
    "            item.append(extract_created(metadata))      #created\n",
    "            item.append(extract_relation(metadata))     #relation\n",
    "            item.append(extract_language(metadata))     #language\n",
    "            \n",
    "            \"\"\"\n",
    "            dict_meta = {}\n",
    "            dict_meta[\"title\"] = extract_title(metadata)\n",
    "            dict_meta[\"creator\"] = extract_creator(metadata)\n",
    "            dict_meta[\"abstract\"] = extract_abstract(metadata)\n",
    "            dict_meta[\"description\"] = extract_description(metadata)\n",
    "            dict_meta[\"contributor\"] = extract_contributor(metadata)\n",
    "            dict_meta[\"created\"] = extract_created(metadata)\n",
    "            dict_meta[\"relation\"] = extract_relation(metadata)\n",
    "            item.append(dict_meta)\n",
    "            \"\"\"\n",
    "        ls.append(item)\n",
    "    return(ls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Scrape function is called and immediately turned into a pandas dataframe.  \n",
    "-DF is given column names  \n",
    "-DF is exported and saved as csv  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>   received from GitHub Pages -> PLUS_Practice-Image-Processing/\n",
      "<Response [200]>   received from GitHub Pages -> VITO_TerraScope_TrainingPack_Application_Example/\n",
      "<Response [200]>   received from GitHub Pages -> VITO_Data_Access_In_Terrascope/\n",
      "<Response [200]>   received from GitHub Pages -> VITO_Cloud_Infrastructure/\n",
      "<Response [200]>   received from GitHub Pages -> GISIG_Introduction_to_EO4GEO/\n",
      "<Response [200]>   received from GitHub Pages -> SpaSe_OBIA-for-Operations-Copernicus-Service-Challenge-Practical-Example/\n",
      "<Response [200]>   received from GitHub Pages -> GEOF_Understanding-the-concept-of-EO-time-series/\n",
      "<Response [200]>   received from GitHub Pages -> GEOF_Basic-GIS-knowledge-vector-and-raster-data/\n",
      "<Response [200]>   received from GitHub Pages -> GEOF_Copernicus-Service-Land/\n",
      "<Response [200]>   received from GitHub Pages -> GEOF_EO-Data-sources/\n",
      "<Response [200]>   received from GitHub Pages -> GEOF_Validation-of-EO-products/\n",
      "<Response [200]>   received from GitHub Pages -> GEOF_Preprocessing-of-EO-data/\n",
      "<Response [200]>   received from GitHub Pages -> GEOF_Legal-issues-in-EO-GI/\n",
      "<Response [200]>   received from GitHub Pages -> UT-ITC_Satellite_Data_Classification_Random_Forests/\n",
      "<Response [200]>   received from GitHub Pages -> UT-ITC_Satellite_Data_Classification_Decision_Trees/\n",
      "<Response [200]>   received from GitHub Pages -> UNEP-GRID_Introduction-to-GIS/\n",
      "<Response [200]>   received from GitHub Pages -> KULeuven_Technical-Introduction-to-SDI/\n",
      "<Response [200]>   received from GitHub Pages -> KULeuven_Management-View-on-SDI/\n",
      "<Response [200]>   received from GitHub Pages -> KULeuven_Introduction-CitizenScience-in-GI-and-EO/\n",
      "<Response [200]>   received from GitHub Pages -> IGIK_Sentinel2-Data-and-Vegetation-Indices/\n",
      "<Response [200]>   received from GitHub Pages -> IGIK_Introduction-to-Remote-Sensing/\n",
      "<Response [200]>   received from GitHub Pages -> ClimateKIC_Copernicus-Service-Climate-Change/\n",
      "<Response [200]>   received from GitHub Pages -> ClimateKIC_Copernicus-Service-Atmosphere/\n",
      "<Response [200]>   received from GitHub Pages -> IES_EO-for-Managers/\n",
      "<Response [200]>   received from GitHub Pages -> FSU-Jena_Persistent-Scaterrer-Interferometry/\n",
      "<Response [200]>   received from GitHub Pages -> FSU-Jena_SAR-Data-for-Flood-Mapping/\n",
      "<Response [200]>   received from GitHub Pages -> ROSA_Change-Detection-in-optical-Data/\n",
      "<Response [200]>   received from GitHub Pages -> UNIBAS_Remote-Sensing-Environment/\n",
      "<Response [200]>   received from GitHub Pages -> UNIBAS_Methods-Techniques-EO/\n",
      "<Response [200]>   received from GitHub Pages -> UJI_Introduction-to-Programming/\n",
      "<Response [200]>   received from GitHub Pages -> UJI_Reproducable-Research-Practices-in-Geosciences/\n",
      "<Response [200]>   received from GitHub Pages -> UJI_AgroMonitoring-with-Geospatial-Data/\n",
      "<Response [200]>   received from GitHub Pages -> PLUS_EO_For_Natural_Hazards/\n",
      "Data sucessfully saved to 'metadata_presentations.csv'\n",
      "Elapsed time in seconds:  6.29\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "#turn resulting list from scrape into pd DataFrame\n",
    "df = pd.DataFrame(scrape(url_list))\n",
    "#Give df columns names\n",
    "df.columns = [\"URL\",\"Added Metadata?\",\"Title\",\"Creator\",\"Abstract\",\"Description\",\"Contributors\",\"Date created\",\"Relation/s\",\"Language\"]\n",
    "#export to csv\n",
    "df.to_csv(\"metadata_presentations.csv\",index=False)\n",
    "#print results\n",
    "#print(\"\\n\\n\",df,\"\\n\\n\")\n",
    "print(\"Data sucessfully saved to 'metadata_presentations.csv'\")\n",
    "print(\"Elapsed time in seconds: \", round(time.time()-start_time,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Format HTML Table with text\n",
    "-Export HTML Table to whole document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_html(meta_df):\n",
    "    header = '''<p><span style=\"text-decoration: underline;\"><strong><img style=\"float: left;\" src=\"http://www.eo4geo.eu/wp-content/uploads/2018/03/logo_site_retina_22.png\" alt=\"EO4GEO Logo\" width=\"220\" height=\"167\" /></strong></span></p>\n",
    "<p>&nbsp;</p>\n",
    "<p>&nbsp;</p>\n",
    "<h4 style=\"text-align: left;\">&nbsp;</h4>\n",
    "<h4 style=\"text-align: left;\">&nbsp;</h4>\n",
    "<h4 style=\"text-align: left;\">&nbsp;</h4>\n",
    "<h4 style=\"text-align: left;\"><span style=\"text-decoration: underline;\"><strong><br />EO4GEO</strong> Course Material Metadata Status<br /></span></h4>\n",
    "<p style=\"text-align: left;\">This table is updated automatically to show the progress of metadata annotations of the slideshows hosted on <br />GitHub Pages/IO.&nbsp;</p>\n",
    "<p style=\"text-align: left;\">&nbsp;</p>\n",
    "<!--HTML TABLE START IN LINDE BELOW-->'''\n",
    "    html = open(\"index.html\",\"w\")\n",
    "    html.write(header)\n",
    "    html.write(meta_df.to_html(index=False,bold_rows=True,justify='center'))\n",
    "\n",
    "def format_html_table(df):\n",
    "    import numpy as np\n",
    "    df_2 = df.copy()\n",
    "    #yes_icon = '<a href=\"https://www.w3schools.com\"><img border=\"0\" alt=\"https://www.eo4geo.sbg.ac.at/PLUS/Practice-Image-Processing/checkmark.png\" width=\"100\" height=\"100\"></a>'\n",
    "    #no_icon = '<a href=\"https://www.w3schools.com\"><img border=\"0\" alt=\"W3Schools\" src=\"https://www.eo4geo.sbg.ac.at/PLUS/Practice-Image-Processing/icon-no.png\" width=\"100\" height=\"100\"></a>'\n",
    "    #Replacing missing titles with logo\n",
    "    df[\"Title\"] = df[\"Title\"].replace(\"\", \"///\")\n",
    "    df[\"Creator\"] = np.where(df[\"Creator\"]!=\"\", \"Yes\", \"///\")\n",
    "    df[\"Abstract\"] = np.where(df[\"Abstract\"]!=\"\", \"Yes\", \"///\")\n",
    "    df[\"Description\"] = np.where(df[\"Description\"]!=\"\", \"Yes\", \"///\")\n",
    "    df[\"Contributors\"] = np.where(df[\"Contributors\"]!=\"\", \"Yes\", \"///\")\n",
    "    df[\"Date created\"] = np.where(df[\"Date created\"]!=\"\", \"Yes\", \"///\")\n",
    "    df[\"Relation/s\"] = np.where(df[\"Relation/s\"]!=\"\", \"Yes\", \"///\")\n",
    "    df[\"Language\"] = df[\"Language\"].replace(\"\", \"///\")\n",
    "    return df_2\n",
    "df_2 = format_html_table(df)\n",
    "\n",
    "write_html(format_html_table(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
